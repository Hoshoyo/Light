#import "linux/print.li"
malloc :: (size : u64) -> ^void #foreign("c");
exit :: (status : s32) -> void #foreign("c");

Tokenizer :: struct {
    stream : string;
    line   : s32;
    column : s32;
    index  : s32;
}

Token :: struct {
    type   : Token_Type;
    data   : string;
    line   : s32;
    column : s32;
}

Token_Type :: enum {
    TOKEN_IDENTIFIER : 1,
    TOKEN_LITERAL_FLOAT : 2,
    TOKEN_SYMBOL : 3,
    TOKEN_COMMENT : 4,
    TOKEN_EOF : 5
}

is_white_space :: (c : u8) -> bool {
    return c == '\n' || c == ' ' || c == '\v' || c == '\t' || c == '\r';
}

is_letter :: (c : u8) -> bool {
    return c >= 'A' && c <= 'Z' || c >= 'a' && c <= 'z';
}

is_number :: (c : u8) -> bool {
    return c >= '0' && c <= '9';
}

token_next :: (tokenizer : ^Tokenizer) -> Token {
    result : Token;
    stream := tokenizer.stream.data;
    index  := tokenizer.index;

    while is_white_space(stream[index]) {
        if stream[index] == '\n' {
            tokenizer.line += 1;
        } else {
            tokenizer.column += 1;
        }
        index += 1;
    }
    
    result.data.capacity = -1;

    if is_letter(stream[index]) {
        start := index;
        while is_letter(stream[index]) || is_number(stream[index]) || stream[index] == '_' {
            index += 1;
            tokenizer.column += 1;
        }
        result.type = Token_Type.TOKEN_IDENTIFIER;
        result.data.length = [s64](index - start);
        result.data.data = stream + start;
    } else if is_number(stream[index]) {
        start := index;
        while is_number(stream[index]) {
            index += 1;
        }
        if stream[index] == '.' {
            index += 1;
            while is_number(stream[index]) {
                index += 1;
            }
        }

        result.type = Token_Type.TOKEN_LITERAL_FLOAT;
        result.data.length = [s64](index - start);
        result.data.data = stream + start;
    } else if stream[index] == 0 {
        result.type = Token_Type.TOKEN_EOF;
        result.data.length = 1;
        result.data.data = stream;
    } else if stream[index] == '#' {
        start := index;
        while stream[index] != '\n' {
            index += 1;
            if stream[index] == 0
                break;
        }
        result.type = Token_Type.TOKEN_COMMENT;
        result.data.length = [s64](index - start);
        result.data.data = stream + start;
    } else {
        result.type = Token_Type.TOKEN_SYMBOL;
        result.data.length = 1;
        result.data.data = stream + index;
        index += 1;
    }

    result.line = tokenizer.line;
    result.column = tokenizer.column;
    tokenizer.index = index;
    return result;
}

string_equal :: (s1 : string, s2 : string) -> bool {
    if s1.length != s2.length return false;
    for i := 0; i < s1.length; i += 1 {
        if s1.data[i] != s2.data[i] return false;
    }
    return true;
}

syntax_error :: (err : string, token : Token) -> s32 {
    print_s32(token.line);
    print_string(":");
    print_s32(token.column);
    print_string(": ");
    print_string(err);
    return -1;
}

/*
token_next_assert :: (tokenizer : ^Tokenizer, type : Token_Type) -> bool {
    token := token_next(tokenizer);
    if token.type != type {
        if type == Token_Type.TOKEN_IDENTIFIER
            syntax_error("Expected identifier token.\n", token);
        else if type == Token_Type.TOKEN_LITERAL_FLOAT
            syntax_error("Expected floating literal token.\n", token);
        else if type == Token_Type.TOKEN_SYMBOL
            syntax_error("Expected symbol token.\n", token);
        return false;
    }
    return true;
}*/

Object :: struct {
    name : string;
    positions : ^vec3;
}

vec3 :: struct {
    x : r32;
    y : r32;
    z : r32;
}

main :: () -> s32 {
    result := read_entire_file("/home/hoshoyo/dev/objloader/cube.obj", malloc);

    tokenizer: Tokenizer;
    tokenizer.stream = result;

    loaded_object : Object;

    while true {
        token := token_next(&tokenizer);

        print_token(token);

        if token.type == Token_Type.TOKEN_COMMENT continue;

        if token.type == Token_Type.TOKEN_IDENTIFIER {
            if string_equal(token.data, "mtllib") {
                // mtllib ignore result of this for now
                material_name := token_next(&tokenizer);
                if material_name.type != Token_Type.TOKEN_IDENTIFIER {
                    return syntax_error("Expected material name.\n", token);
                }
                dot := token_next(&tokenizer);
                if dot.type == Token_Type.TOKEN_SYMBOL {
                    material_extension := token_next(&tokenizer);
                    if material_extension.type != Token_Type.TOKEN_SYMBOL {
                        return syntax_error("Expected extension for material.\n", material_extension);
                    }
                }
            } else if string_equal(token.data, "o") {
                // name of the object
                object_name := token_next(&tokenizer);
                if object_name.type != Token_Type.TOKEN_IDENTIFIER {
                    return syntax_error("Expected object name.\n", object_name);
                }
                loaded_object.name = object_name.data;
            } else if string_equal(token.data, "v") {
                // vertice
            }
        }

        if token.type == Token_Type.TOKEN_EOF {
            break;
        }
    }

    return 0;
}

print_token :: (t : Token) -> void {
    print_s32(t.line + 1);
    print_string(":");
    print_s32(t.column);
    print_string(": ");

    if t.type == Token_Type.TOKEN_IDENTIFIER {
        print_string("Identifier: ");
        print_string(t.data);
    } else if t.type == Token_Type.TOKEN_LITERAL_FLOAT {
        print_string("Float: ");
        print_string(t.data);
    } else if t.type == Token_Type.TOKEN_SYMBOL {
        print_string("Symbol: ");
        print_string(t.data);
    } else if t.type == Token_Type.TOKEN_EOF {
        print_string("EOF");
    } else if t.type == Token_Type.TOKEN_COMMENT {
        print_string("Comment: ");
        print_string(t.data);
    }
    print_string("\n");
}