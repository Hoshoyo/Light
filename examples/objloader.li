#import "linux/print.li"
malloc :: (size : u64) -> ^void #foreign("c");
exit :: (status : s32) -> void #foreign("c");

Tokenizer :: struct {
    stream : string;
    line   : s32;
    column : s32;
    index  : s32;
}

Token :: struct {
    type   : Token_Type;
    data   : string;
    line   : s32;
    column : s32;
}

Token_Type :: enum {
    TOKEN_IDENTIFIER : 1,
    TOKEN_LITERAL_FLOAT : 2,
    TOKEN_SYMBOL : 3,
    TOKEN_COMMENT : 4,
    TOKEN_EOF : 5
}

is_white_space :: (c : u8) -> bool {
    return c == '\n' || c == ' ' || c == '\v' || c == '\t' || c == '\r';
}

is_letter :: (c : u8) -> bool {
    return c >= 'A' && c <= 'Z' || c >= 'a' && c <= 'z';
}

is_number :: (c : u8) -> bool {
    return c >= '0' && c <= '9';
}

token_next :: (tokenizer : ^Tokenizer) -> Token {
    result : Token;
    stream := tokenizer.stream.data;
    index  := tokenizer.index;

    while is_white_space(stream[index]) {
        if stream[index] == '\n' {
            tokenizer.line += 1;
        } else {
            tokenizer.column += 1;
        }
        index += 1;
    }
    
    result.data.capacity = -1;

    if is_letter(stream[index]) {
        start := index;
        while is_letter(stream[index]) || is_number(stream[index]) || stream[index] == '_' {
            index += 1;
            tokenizer.column += 1;
        }
        result.type = Token_Type.TOKEN_IDENTIFIER;
        result.data.length = [s64](index - start);
        result.data.data = stream + start;
    } else if is_number(stream[index]) {
        start := index;
        while is_number(stream[index]) {
            index += 1;
        }
        if stream[index] == '.' {
            index += 1;
            while is_number(stream[index]) {
                index += 1;
            }
        }

        result.type = Token_Type.TOKEN_LITERAL_FLOAT;
        result.data.length = [s64](index - start);
        result.data.data = stream + start;
    } else if stream[index] == 0 {
        result.type = Token_Type.TOKEN_EOF;
        result.data.length = 1;
        result.data.data = stream;
    } else if stream[index] == '#' {
        start := index;
        while stream[index] != '\n' {
            index += 1;
            if stream[index] == 0
                break;
        }
        result.type = Token_Type.TOKEN_COMMENT;
        result.data.length = [s64](index - start);
        result.data.data = stream + start;
    } else {
        result.type = Token_Type.TOKEN_SYMBOL;
        result.data.length = 1;
        result.data.data = stream + index;
        index += 1;
    }

    result.line = tokenizer.line;
    result.column = tokenizer.column;
    tokenizer.index = index;
    return result;
}

string_equal :: (s1 : string, s2 : string) -> bool {
    if s1.length != s2.length return false;
    for i := 0; i < s1.length; i += 1 {
        if s1.data[i] != s2.data[i] return false;
    }
    return true;
}

syntax_error :: (err : string, token : Token) -> s32 {
    print_s32(token.line);
    print_string(":");
    print_s32(token.column);
    print_string(": Syntax Error:");
    print_string(err);
    return -1;
}

parse_s32 :: (tokenizer : ^Tokenizer, out_int : ^s32) -> s32 {
    i : s64;
    r := parse_s64(tokenizer, &i);
    *out_int = [s32]i;
    return r;
}

parse_s64 :: (tokenizer : ^Tokenizer, out_int : ^s64) -> s32 {
    token := token_next(tokenizer);
    sign := 1;

    if token.type == Token_Type.TOKEN_SYMBOL && token.data.data[0] == '-' {
        sign = -1;
        token = token_next(tokenizer);
    }
    if token.type != Token_Type.TOKEN_LITERAL_FLOAT {
        return syntax_error("expected integer", token);
    }

    result := 0;
    multiplier := 10;

    for i := 0; i < token.data.length; i += 1 {
		result += [s64](token.data.data[i] - 0x30);
		multiplier *= multiplier;
	}
    *out_int = result * sign;
    return 0;
}

parse_float :: (tokenizer : ^Tokenizer, out_r32 : ^r32) -> s32 {
    token := token_next(tokenizer);

    sign := 1.0;

    if token.type == Token_Type.TOKEN_SYMBOL && token.data.data[0] == '-' {
        sign = -1.0;
        token = token_next(tokenizer);
    }
    if token.type != Token_Type.TOKEN_LITERAL_FLOAT {
        return syntax_error("expected float token", token);
    }

    result := 0.0;
	multiplier := 10.0;
	m := 1.0;

	for i := 0; i < token.data.length; i += 1 {
		if token.data.data[i] == '.' {
			multiplier = 0.1;
			m = 0.1;
			continue;
		}
		result += m * [r32](token.data.data[i] - 0x30);
		m *= multiplier;
	}

    *out_r32 = result * sign;
    return 0;
}

expect_symbol :: (tokenizer : ^Tokenizer, symbol : u8) -> s32 {
    token := token_next(tokenizer);

    if token.type != Token_Type.TOKEN_SYMBOL || token.data.data[0] != symbol {
        return syntax_error("expected symbol ", token);
    }

    return 0;
}

Object :: struct {
    name : string;
    positions : ^vec3;
}

vec3 :: struct {
    x : r32;
    y : r32;
    z : r32;
}

vec2 :: struct {
    x : r32;
    y : r32;
}

ivec3 :: struct {
    x : s32;
    y : s32;
    z : s32;
}

main :: () -> s32 {
    result := read_entire_file("/home/hoshoyo/dev/objloader/cube.obj", malloc);

    tokenizer: Tokenizer;
    tokenizer.stream = result;

    loaded_object : Object;

    while true {
        token := token_next(&tokenizer);

        print_token(token);

        if token.type == Token_Type.TOKEN_COMMENT continue;

        if token.type == Token_Type.TOKEN_IDENTIFIER {
            if string_equal(token.data, "mtllib") {
                // mtllib ignore result of this for now
                material_name := token_next(&tokenizer);
                if material_name.type != Token_Type.TOKEN_IDENTIFIER {
                    return syntax_error("Expected material name.\n", token);
                }
                dot := token_next(&tokenizer);
                if dot.type == Token_Type.TOKEN_SYMBOL {
                    material_extension := token_next(&tokenizer);
                    if material_extension.type != Token_Type.TOKEN_IDENTIFIER {
                        return syntax_error("Expected extension for material.\n", material_extension);
                    }
                }
            } else if string_equal(token.data, "o") {
                // name of the object
                object_name := token_next(&tokenizer);
                if object_name.type != Token_Type.TOKEN_IDENTIFIER {
                    return syntax_error("Expected object name.\n", object_name);
                }
                loaded_object.name = object_name.data;
            } else if string_equal(token.data, "g") {
                // name of the object
                object_name := token_next(&tokenizer);
                if object_name.type != Token_Type.TOKEN_IDENTIFIER {
                    return syntax_error("Expected object name.\n", object_name);
                }
                loaded_object.name = object_name.data;
            } else if string_equal(token.data, "v") {
                // vertice
                v : vec3;
                parse_float(&tokenizer, &v.x);
                parse_float(&tokenizer, &v.y);
                parse_float(&tokenizer, &v.z);

                print_vec3(v);
            } else if string_equal(token.data, "vt") {
                // texture coordinate
                v : vec2;
                parse_float(&tokenizer, &v.x);
                parse_float(&tokenizer, &v.y);

                print_vec2(v);
            } else if string_equal(token.data, "vn") {
                // normals
                v : vec3;
                parse_float(&tokenizer, &v.x);
                parse_float(&tokenizer, &v.y);
                parse_float(&tokenizer, &v.z);

                print_vec3(v);
            } else if string_equal(token.data, "s") {
                v : s64;
                parse_s64(&tokenizer, &v);
                print_s64(v);
            } else if string_equal(token.data, "f") {
                // face / triangle
                face : [3]ivec3;
                for f := 0; f < 3; f += 1 {
                    // int / int / int
                    err := parse_s32(&tokenizer, &face[f].x);
                    if err != 0 return -1;
                    expect_symbol(&tokenizer, '/');
                    err = parse_s32(&tokenizer, &face[f].y);
                    if err != 0 return -1;
                    expect_symbol(&tokenizer, '/');
                    err = parse_s32(&tokenizer, &face[f].z);
                    if err != 0 return -1;
                }
            }
        }

        if token.type == Token_Type.TOKEN_EOF {
            break 1;
        }
    }

    return 0;
}

print_vec3 :: (v : vec3) {
    print_string("{");
    print_r32(v.x);
    print_string(", ");
    print_r32(v.y);
    print_string(", ");
    print_r32(v.z);
    print_string("}");
}

print_vec2 :: (v : vec2) {
    print_string("{");
    print_r32(v.x);
    print_string(", ");
    print_r32(v.y);
    print_string("}");
}

print_token :: (t : Token) -> void {
    print_s32(t.line + 1);
    print_string(":");
    print_s32(t.column);
    print_string(": ");

    if t.type == Token_Type.TOKEN_IDENTIFIER {
        print_string("Identifier: ");
        print_string(t.data);
    } else if t.type == Token_Type.TOKEN_LITERAL_FLOAT {
        print_string("Float: ");
        print_string(t.data);
    } else if t.type == Token_Type.TOKEN_SYMBOL {
        print_string("Symbol: ");
        print_string(t.data);
    } else if t.type == Token_Type.TOKEN_EOF {
        print_string("EOF");
    } else if t.type == Token_Type.TOKEN_COMMENT {
        print_string("Comment: ");
        print_string(t.data);
    }
    print_string("\n");
}

/*
main :: () -> s32 {
    entry : s32 = 3;

    // create hash table
    hash_table := hash_table_create([^Type_Info]#typeof entry);

    ei := hash_table_push(hash_table, &entry, #sizeof s32);
    hash_table_remove(hash_table, &entry, #sizeof s32);

    // check entry existence
    if hash_table_entry_exist(hash_table, &entry, #sizeof s32, null) {
        print_string("Entry exists!\n");
    } else {
        print_string("Entry does not exist.\n");
    }

    // delete hash table
    hash_table_delete(hash_table);
    return 0;
}
*/